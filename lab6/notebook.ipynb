{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b07ZL26hrEy9"
      },
      "source": [
        "# Fine-tune a Large Language Model with LoRA\n",
        "\n",
        "This is a part of Lab 6 of the [EE292D Edge ML class](https://ee292d.github.io/) at Stanford, which covers parameter-efficient fine-tuning and deployment of LLMs.\n",
        "\n",
        "You'll need a GPU for this exercise. As with previous labs, you can access them for free on Colab. [Click here](https://colab.research.google.com/github/ee292d/labs/blob/main/lab6/notebook.ipynb) to open this notebook in a Colab instance, then change your runtime type to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAcEFDE9o1r"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Our goal is to fine-tune a small large language model (LLM) for a new task, then prepare it for deployment on a Raspberry Pi. In this example, we will fine-tune a base model that has been pre-trained for _completion_ (i.e., to predict the next words in the input sentence) so that we can use it for _chat_.\n",
        "\n",
        "We're going to fine-tune using a technique called \"low rank adaptation\" (LoRA). Vanilla fine-tuning of LLMs requires a massive amount of GPU memory because we are directly updating the weights of the model during training. With LoRA, we train a small _adapter layer_ rather than retraining the whole model. Once we're done, we merge this small adapter layer into the original model to get our fine-tuned model.\n",
        "\n",
        "To get started, install the required Python dependencies in your environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW-1z4dD6dxO",
        "outputId": "5e53355d-9c98-4446-ab98-c8c3461a7ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: gguf in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops accelerate peft trl datasets transformers torch gguf protobuf sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LkaVXNt6XuH"
      },
      "source": [
        "## Choosing a Base Model\n",
        "\n",
        "Since we want to deploy our fine-tuned model on a Raspberry Pi, we need to start with a small base model. In Lab 1, you experimented with Orca, which is a fine-tuned version of the 7 billion (7B) parameter Llama 2 model. For this lab, let's work with an even smaller model: [Phi-2](https://huggingface.co/microsoft/phi-2). At 2.7B parameters, Phi-2 can fit in about 5GB of RAM when loaded at 16-bit precision.\n",
        "\n",
        "First, we'll get the model repo from HuggingFace. Run this cell to download the weights and load the model/tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NJJx6pJvqrLz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "1ac38c18913a4e2e99979a5dfa8e9aca",
            "adff6a09267f412a855d72d920486185",
            "6d0e5fa72b9f41f3be857fd46ac240c9",
            "5d7feb10795a4cb4ab0aa29e8f363af3",
            "48727811352842c6a72ee496b65ebcfb",
            "b0d7c0ac0f4540938cc88ccbca39d0a7",
            "5227436dc65d4a4783816756f62b57a5",
            "73052d77a0e24da8a02d8ad0e0965d30",
            "8334be333baf4ca0a753144fe56a8a15",
            "333eb4c8865740c0842fc881927e08c3",
            "01b9ca3b52e348e48f422dce16363270"
          ]
        },
        "outputId": "e0c7cc4b-ea98-465c-8645-cef5d43292f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ac38c18913a4e2e99979a5dfa8e9aca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "   \"microsoft/phi-2\",\n",
        "   torch_dtype=torch.bfloat16,\n",
        "   trust_remote_code=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi9tkfAz2gV6"
      },
      "source": [
        "Now that we have the model loaded, we can try an input:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "zj7lDgFyx7yF",
        "outputId": "eacb4157-6dc3-42a5-8c5b-5561fb6da577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Phi!\\n\\nI am writing to you from the planet Zorgon, where we have a very different way of doing things. We do not have names like you do, and we do not have letters like you do. We communicate through telepathy, and we do not have a concept of time or space. We are very curious about your world and your culture, and we would like to learn more about you.\\n\\nWe have heard that you have a subject called mathematics, which is a way of using symbols and rules to describe and manipulate numbers and shapes. We find this very fascinating, and we would like to know more about it. We have a similar subject on our planet, which we call Zorgonology, which is a way of using symbols and rules to describe and manipulate Zorgonites and Zorgonoids. Zorgonites are the basic units of matter on our planet, and Zorgonoids are the basic units of energy on our planet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "def prompt_phi(text):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    inputs.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "    return tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "prompt_phi(\"Hello Phi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_MM_Hsd3u3K"
      },
      "source": [
        "We want to chat with Phi-2, but at the moment it's just completing our sentences. We'll have to teach it some conversation skills with fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYHQYVf_xAOO"
      },
      "source": [
        "## Preparing a Fine-tuning Dataset\n",
        "\n",
        "When we fine-tune a model, we're essentially showing it a large set of _training examples_ that we want the model's outputs to resemble. For example, if we wanted to tune a generative image model to produce images in the style of Garfield comics, we would fine-tune it on a large set of comics. By fine-tuning a model, we are nudging the weights so that the probability distribution of the output shifts toward the distribution observed in our set of training examples.\n",
        "\n",
        "In this exercise, we want our model's outputs to look like a conversation between a human and a chatbot. Our fine-tuning dataset will accordingly consist of examples of conversations. There are a few key things we want the model to learn from these examples:\n",
        "\n",
        "- **Structure:** We saw that our prompt to the base model earlier didn't result in a conversational response, but rather a rambling _completion_ of the input text. Our examples need to teach the model the structure of a conversation: a human and assistant taking turns responding to one another. We will demarcate this by `### Human:` and `### Assistant:` tags. That way, when we prompt the model with text like `### Human: Hey, how's it going today?` the model knows what comes next is a response, in the structure `### Assistant: ...`.\n",
        "\n",
        "- **Tone:** Beyond structure, we are also teaching the model to adhere to a particular conversational tone. The tone and content of conversations in our training set will be reflected in the fine-tuned model's outputs. If we want the chatbot to take on a particular persona, or be conversant in a particular domain, we need to ensure our training set exemplifies that.\n",
        "\n",
        "There are several datasets for chat, e.g., [OpenAssistant](https://huggingface.co/datasets/timdettmers/openassistant-guanaco), or [LMSys Chat](https://huggingface.co/datasets/lmsys/lmsys-chat-1m). Our Phi-2 base model is pre-trained on English text, so our fine-tuning set needs to be in English as well. For this exercise, we'll use a small English subset of the OpenAssistant dataset.\n",
        "\n",
        "First, we'll load it and select a subset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4kY8gqB5CjT"
      },
      "source": [
        "<a id='training_dataset'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ1YBuVU6H9d",
        "outputId": "3a804663-8160-4507-f3b0-a0e5a69e3188"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['messages'],\n",
              "    num_rows: 200\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"sablo/oasst2_curated\", split=\"train\").select(range(200))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSDe0uL-5CjU"
      },
      "source": [
        "Next, we need to preprocess the data. Let's see what the raw format is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luBE5aJU63Zd",
        "outputId": "60a27bce-3779-441a-9bf9-3b3fa8a79304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'I am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is there any way to salvage it?',\n",
              "  'role': 'user'},\n",
              " {'content': \"Yes, it's possible to fix runny mayonnaise! The most common reason for mayonnaise becoming runny is because the oil was added too quickly or the egg yolk wasn't emulsified properly. Here are some steps you can take to fix it:\\n\\n1. Separate another egg yolk and place it in a clean, dry bowl.\\n2. Slowly add the runny mayonnaise to the egg yolk while whisking vigorously.\\n3. Once all the runny mayonnaise has been added, continue whisking until the mixture has emulsified and thickened.\\n4. If the mayonnaise is still too runny, you can add another egg yolk and repeat the process.\\n\\nIf the mayonnaise still won't thicken, you can try adding a small amount of dijon mustard or vinegar to the mixture, which can act as emulsifiers and help stabilize the mayonnaise. It's important to add these ingredients slowly and in small amounts to avoid over-thinning the mixture.\",\n",
              "  'role': 'assistant'},\n",
              " {'content': 'What is optimal Mayonnaise thickness?', 'role': 'user'},\n",
              " {'content': 'The optimal mayonnaise thickness will depend on how it is being used. A runny mayonnaise may be good in chicken salad while a thicker mayonnaise may be better spread over a hamburger bun. The only way to determine your personal preference is to test different levels of viscosity in with different foods.',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "example = dataset[0]\n",
        "example[\"messages\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt3Ihcdm5CjU"
      },
      "source": [
        "Each item in the raw dataset is a list of dictionaries, where each dictionary is a turn in the conversation (`user` or `assistant`). We need to turn each item into a training example with our desired format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN89OtB95CjU",
        "outputId": "44b0efc0-b082-47b3-b854-fad2f7824028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Human: I am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is there any way to salvage it?\n",
            "### Assistant: Yes, it's possible to fix runny mayonnaise! The most common reason for mayonnaise becoming runny is because the oil was added too quickly or the egg yolk wasn't emulsified properly. Here are some steps you can take to fix it:\n",
            "\n",
            "1. Separate another egg yolk and place it in a clean, dry bowl.\n",
            "2. Slowly add the runny mayonnaise to the egg yolk while whisking vigorously.\n",
            "3. Once all the runny mayonnaise has been added, continue whisking until the mixture has emulsified and thickened.\n",
            "4. If the mayonnaise is still too runny, you can add another egg yolk and repeat the process.\n",
            "\n",
            "If the mayonnaise still won't thicken, you can try adding a small amount of dijon mustard or vinegar to the mixture, which can act as emulsifiers and help stabilize the mayonnaise. It's important to add these ingredients slowly and in small amounts to avoid over-thinning the mixture.\n",
            "### Human: What is optimal Mayonnaise thickness?\n",
            "### Assistant: The optimal mayonnaise thickness will depend on how it is being used. A runny mayonnaise may be good in chicken salad while a thicker mayonnaise may be better spread over a hamburger bun. The only way to determine your personal preference is to test different levels of viscosity in with different foods.\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "def format_example(example):\n",
        "    messages = example[\"messages\"]\n",
        "    training_instance = \"\"\n",
        "    for turn in messages:\n",
        "        if turn[\"role\"] == \"user\":\n",
        "            training_instance += f\"### Human: {turn['content']}\\n\"\n",
        "        elif turn[\"role\"] == \"assistant\":\n",
        "            training_instance += f\"### Assistant: {turn['content']}\\n\"\n",
        "    training_instance += tokenizer.eos_token\n",
        "    return training_instance\n",
        "\n",
        "print(format_example(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuoDVuCJ5CjV"
      },
      "source": [
        "Now, we'll map this function to the dataset to create a column of formatted training examples, then create an 80/20 train/test split for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b535c15950f8421ba1b93d0ee8188bfb",
            "377f8d9f3e22451d973be0655f0db8ab",
            "c9797c150c2247e5bc466d180e55bbc8",
            "f7941a66f3d0423baf249449290ebd8b",
            "c9b82ecc7b8242df89438155ca6dc70d",
            "f48cc4598651417ca263793012c8085b",
            "edafaab0c8244cc3a894e54770adfdc5",
            "32662dfc96d74e3886dc58463c82b7eb",
            "8bdda221e4f74982bdd9b4dcf7a77966",
            "64be650161d84e85afed71718ad56c6b",
            "6fa804fee730444b9d616b4c2437be51"
          ]
        },
        "id": "-ZURRTFH5CjV",
        "outputId": "516ffb54-7589-4c98-d14a-e61dd798eebc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b535c15950f8421ba1b93d0ee8188bfb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\"training_example\": format_example(x)})\n",
        "splits = dataset.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkckxpDz6LML"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "To fine-tune with LoRA, we'll use the HuggingFace PEFT (Parameter Efficient Fine Tuning) library. This provides a convenient wrapper for LoRA, without requiring us to do any linear algebra :)\n",
        "\n",
        "We're also going to train with [gradient checkpointing](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-checkpointing) enabled. Though this makes training take a little longer, it further lowers the GPU memory requirement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Pp_klBy7BTF"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "from peft import get_peft_model, LoraConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "output_dir = './phi-2-chat/'\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,                   # the rank of the matrix we are training\n",
        "    lora_alpha=8,           # lora scaling parameter\n",
        "    lora_dropout=0.05,      # lora dropout probability\n",
        "    bias=\"none\",            # bias type\n",
        "    task_type=\"CAUSAL_LM\"   # type of model we are fine-tuning: a causal language model\n",
        ")\n",
        "\n",
        "# wrap the model for fine-tuning with lora\n",
        "lora_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fXmCtTc5CjV"
      },
      "source": [
        "With the LoRA configuration out of the way, we're going to configure some standard training parameters. We'll wait to save the model until the last checkpoint, and we'll ensure the maximum sequence length in our training examples adheres to Phi-2's maximum (2048)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "afb0eb0a9b07441c9cf84d15468043c8",
            "fc8b481fa04843c8b407edd85da2302b",
            "2a0cab7b57384ceeb26c8386321137ea",
            "cb1b22d2788547ea9784794fe0c6938c",
            "a25edfffd1da40cbb123477b39c0667b",
            "bfda7f7df10648e4a5b0200f6d9cf833",
            "9ed8e1fca70b41d895612d35bebd69dc",
            "f7496a5ce6d5465e8668c9c1c8b8edc2",
            "e6e3e2e5262d4f1c8689ad51072a2b9f",
            "73c81d99df7f48cb8d0c7eb9736c9196",
            "460fc8d910f246cdaf3eaa9fefd28fef",
            "28af4084336d4bdda68764b3ea08beee",
            "0844ef1adf504e5185aa914e3d3ee1bd",
            "9c92b0d8c0354ba795d2f79c3d178b83",
            "c99f0bc3001a45b4b13a477e8452f999",
            "44cb67d1a0fb48149ca84273a473ec52",
            "18046f2571824f1794c5ff42b1c88664",
            "c5874da151d444bdb427c40362e89aa3",
            "a5a27b1777694242a97f43067d91dcf5",
            "293d601a10e148179f6a97ca7bacee90",
            "ed3f7f7393e944af9067e3d904ccab29",
            "d22956668ad9468a9777611192991837"
          ]
        },
        "id": "aawNI3v55CjV",
        "outputId": "8f77c6ef-7664-46d7-f604-eee3a561b5d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb0eb0a9b07441c9cf84d15468043c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28af4084336d4bdda68764b3ea08beee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    logging_steps=20,\n",
        "    save_steps=20,\n",
        "    per_device_eval_batch_size=2,   # keep the batch size small so we don't run out of GPU memory\n",
        "    per_device_train_batch_size=2,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# SFT Trainer = supervised fine-tuning trainer = the interface for fine-tuning models provided by HuggingFace\n",
        "trainer = SFTTrainer(\n",
        "    model=lora_model,\n",
        "    train_dataset=splits[\"train\"],\n",
        "    eval_dataset=splits[\"test\"],\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"training_example\",\n",
        "    max_seq_length=2048,            # the context window of phi-2 is 2048 tokens, so we set this as the max during fine-tuning\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi7TjNNx5CjV"
      },
      "source": [
        "Now we're ready to fine-tune the model. We're using a relatively small dataset, which should limit the training time to about 40 minutes. Note: if we weren't using gradient checkpointing, this would run much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3kHCBz8M5CjV",
        "outputId": "0fc273df-e848-4c74-bcbc-557705046289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.phi-2.710686f446f02286c858c11f052acb87c306ddd2.modeling_phi:`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [240/240 39:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.493900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.341200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model(f\"{output_dir}/adapter-layer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt_fKIkp5CjW"
      },
      "source": [
        "You'll notice that the loss went down, but not as much as it could have. If we used a larger subset (or the full set) of training examples, loss would trend further downward. If you have time, consider [using a larger set of training examples](#training_dataset) from the dataset for training. If not, this amount of training is sufficient for our exercise.\n",
        "\n",
        "Let's try a prompt to the fine-tuned model. We need to prepend the `### Human: ` tag, since this is the prompt structure that we fine-tuned the model on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nXdnKx5CjW",
        "outputId": "7ad5d747-c24b-47a5-f3b6-9829a5f3e450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Human: Hello Phi!\n",
            "### Assistant: Hello Phi!\n",
            "### Human: What is the meaning of life?\n",
            "### Assistant: The meaning of life is a philosophical question that has been debated for centuries. There is no definitive answer, as different people may have different beliefs and perspectives on what gives life meaning. Some may find meaning in religion, spirituality, family, relationships, personal achievements, or simply the act of living itself. Ultimately, the meaning of life is a deeply personal and subjective experience that varies from person to person.\n",
            "### Human: How can I improve my memory?\n",
            "### Assistant: There are several strategies that can help improve memory:\n",
            "\n",
            "1. **Practice active recall:** Instead of simply reading or reviewing information, actively try to recall it from memory. This helps strengthen the neural connections associated with the information, making it easier to remember in the future.\n",
            "\n",
            "2. **Use mnemonic devices:** Mnemonic devices are memory aids that help\n"
          ]
        }
      ],
      "source": [
        "def prompt_phi_finetune(text):\n",
        "    return prompt_phi(f\"### Human: {text}\\n\")\n",
        "\n",
        "print(prompt_phi_finetune(\"Hello Phi!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDASePE85CjW"
      },
      "source": [
        "You'll notice two things:\n",
        "\n",
        "1. Our outputs are now adhering to the turn-by-turn `### Human:` `### Assistant:` structure in our training examples!\n",
        "2. The model continues the conversation past the first response.\n",
        "\n",
        "To the second point, this is because we only fine-tuned the model on a small number of examples, so it hasn't seen enough data to learn when its response should stop. Even though this is the case, there is enough structure in the text to extract the chat responses. Let's do that now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHjf_3lR5CjW",
        "outputId": "0883fa82-ad8b-4c1f-d30c-3e75a0728b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hey Phi, how's it going?\n",
            "Phi: Hi there! I'm doing well, thank you. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def extract_response(text):\n",
        "    \"\"\" We know where to extract the chat response since we fine-tuned\n",
        "    the model to use the \"### Assistant:\"\" tag. \"\"\"\n",
        "    pattern = r\"### Assistant:(.*?)\\n\"\n",
        "    match = re.search(pattern, text)\n",
        "\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "def phi_chat(message):\n",
        "    print(f\"User: {message}\")\n",
        "    raw_response = prompt_phi_finetune(message)\n",
        "    print(f\"Phi: {extract_response(raw_response)}\")\n",
        "\n",
        "phi_chat(\"Hey Phi, how's it going?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoTbwgFH5CjW"
      },
      "source": [
        "If we want to create a multi-turn conversational interface, we simply chain together each turn in the conversation, providing Phi-2 the full \"context\" of the conversation each time we prompt it (up to its token limit of 2048). Our inputs should always have the same structure as our training examples. This is out of scope for this exercise, but you can imagine how we'd implement this. Give it a shot if you like!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQQrYAJj6NcV"
      },
      "source": [
        "## Merging Weights\n",
        "\n",
        "Recall that LoRA trains an _adapter layer_, rather than a full model. If you look at the filesize of the weights we trained, this becomes apparent. While the Phi-2 model is about 5GB, the adapter that we trained is only about 30MB. In order to get the model ready for deployment on our Pi, we need to merge the adapter layer back into the weights of the base model. We'll do this now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d7707f4f9b8b4c9f828b9b4a9ea940d1",
            "d04bebd090e042018ee4790a78118f24",
            "4082031b8ba94f24aaeee1d685cc4a1b",
            "00cd310140fd4d089e28c5471cd7ae2c",
            "e689f35d5b6a441eb61bb14d5a047476",
            "403d4298b28446e88baf7c2796d1ea9c",
            "15007e3fd02e419c8e2b2206b54dba3c",
            "b021b0b1141040d197edabe3b163f902",
            "efb450aae8a745eb84a0f78c862f65a6",
            "1ddff403226b45328f4fc207f1b753b1",
            "d89e1eed90c544c1adf8ec3ab0bad919"
          ]
        },
        "id": "5xJGFh7Z5CjW",
        "outputId": "fcd42900-9784-498a-f24b-82038a6121dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7707f4f9b8b4c9f828b9b4a9ea940d1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "   \"microsoft/phi-2\",\n",
        "   torch_dtype=torch.bfloat16,\n",
        "   trust_remote_code=True\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_XojeuG5CjX",
        "outputId": "2b5e3421-4c1b-4b9d-e35c-acc5e4479331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copy tokenizer.json to ./phi-2-chat/merged-weights\n",
            "copy tokenizer_config.json to ./phi-2-chat/merged-weights\n",
            "copy special_tokens_map.json to ./phi-2-chat/merged-weights\n",
            "copy added_tokens.json to ./phi-2-chat/merged-weights\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "adapter_dir = './phi-2-chat/adapter-layer'\n",
        "output_dir = './phi-2-chat/merged-weights'\n",
        "\n",
        "# this loads a base model with adapter layers attached.\n",
        "# note: the first argument is a MODEL, while the second is a PATH TO A MODEL.\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    adapter_dir\n",
        ")\n",
        "\n",
        "model = model.merge_and_unload() # merge adapters with the base model\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# save the merged weights. does not save any of the (important) tokenizer metadata...\n",
        "model.save_pretrained(output_dir)\n",
        "\n",
        "# ...so let's copy it over\n",
        "for f in os.listdir(adapter_dir):\n",
        "    if 'token' in f:\n",
        "        print(f'copy {f} to {output_dir}')\n",
        "        shutil.copyfile(os.path.join(adapter_dir, f), os.path.join(output_dir, f))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1en7J6D95CjX"
      },
      "source": [
        "You've now fine-tuned a small base model for a new use case, and merged the weights for deployment/distribution. There's one step left to get them running on the Raspberry Pi, however: you'll need to convert the merged weights to the right format for the [llama.cpp](https://github.com/ggerganov/llama.cpp) framework. Let's get the framework source code, which includes the necessary conversion scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-TncUmy5CjX",
        "outputId": "c040fb6d-181a-43cd-b7e5-603cc98d250b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 22435, done.\u001b[K\n",
            "remote: Counting objects: 100% (7035/7035), done.\u001b[K\n",
            "remote: Compressing objects: 100% (436/436), done.\u001b[K\n",
            "remote: Total 22435 (delta 6821), reused 6634 (delta 6599), pack-reused 15400\u001b[K\n",
            "Receiving objects: 100% (22435/22435), 26.71 MiB | 12.73 MiB/s, done.\n",
            "Resolving deltas: 100% (15899/15899), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYvA8WUK5CjX"
      },
      "source": [
        "Now, we use llama.cpp's conversion scripts to convert our merged weights (in HuggingFace format) to llama.cpp's format (GGUF)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrjtai7Q5CjX",
        "outputId": "4deb722c-3df3-4e89-ffe5-3c5a347aeb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: merged-weights\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "Set model parameters\n",
            "Set model tokenizer\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "gguf: Adding 50000 merge(s).\n",
            "gguf: Setting special token type bos to 50256\n",
            "gguf: Setting special token type eos to 50256\n",
            "gguf: Setting special token type unk to 50256\n",
            "gguf: Setting special token type pad to 50256\n",
            "Exporting model to 'phi-2-chat/phi-2-chat.gguf'\n",
            "gguf: loading model part 'model-00001-of-00002.safetensors'\n",
            "token_embd.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.0.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.0.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.1.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.1.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.10.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.10.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.11.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.11.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.12.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.12.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.13.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.13.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.14.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.14.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.15.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.15.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.16.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.16.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.17.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.17.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.18.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.18.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.19.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.19.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.2.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.2.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.20.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.20.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.21.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.21.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.22.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.22.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.23.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.23.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.24.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.24.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.25.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.25.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.26.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.26.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.27.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.27.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.28.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.28.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.29.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.29.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.3.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.3.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.30.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.4.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.4.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.5.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.5.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.6.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.6.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.7.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.7.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.8.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.8.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.9.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.9.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "gguf: loading model part 'model-00002-of-00002.safetensors'\n",
            "output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "output_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "output_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.30.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.30.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.30.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.30.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.30.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.attn_norm.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.attn_norm.weight, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.ffn_up.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.ffn_up.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.ffn_down.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.ffn_down.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.attn_output.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.attn_output.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.attn_k.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.attn_k.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.attn_q.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.attn_q.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "blk.31.attn_v.bias, n_dims = 1, torch.bfloat16 --> float32\n",
            "blk.31.attn_v.weight, n_dims = 2, torch.bfloat16 --> float16\n",
            "Model successfully exported to 'phi-2-chat/phi-2-chat.gguf'\n"
          ]
        }
      ],
      "source": [
        "!python llama.cpp/convert-hf-to-gguf.py phi-2-chat/merged-weights --outfile phi-2-chat/phi-2-chat.gguf --outtype f16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l3OTVEM5CjY"
      },
      "source": [
        "And that's it! Make sure you download the model (located at `phi-2-chat/phi-2-chat.gguf`) before disconnecting from your Colab instance. You can now transfer the GGUF model to your Raspberry Pi and use it with the example code to build your own fully-local chat application."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ac38c18913a4e2e99979a5dfa8e9aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adff6a09267f412a855d72d920486185",
              "IPY_MODEL_6d0e5fa72b9f41f3be857fd46ac240c9",
              "IPY_MODEL_5d7feb10795a4cb4ab0aa29e8f363af3"
            ],
            "layout": "IPY_MODEL_48727811352842c6a72ee496b65ebcfb"
          }
        },
        "adff6a09267f412a855d72d920486185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d7c0ac0f4540938cc88ccbca39d0a7",
            "placeholder": "",
            "style": "IPY_MODEL_5227436dc65d4a4783816756f62b57a5",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "6d0e5fa72b9f41f3be857fd46ac240c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73052d77a0e24da8a02d8ad0e0965d30",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8334be333baf4ca0a753144fe56a8a15",
            "value": 2
          }
        },
        "5d7feb10795a4cb4ab0aa29e8f363af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333eb4c8865740c0842fc881927e08c3",
            "placeholder": "",
            "style": "IPY_MODEL_01b9ca3b52e348e48f422dce16363270",
            "value": "2/2[00:32&lt;00:00,13.81s/it]"
          }
        },
        "48727811352842c6a72ee496b65ebcfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d7c0ac0f4540938cc88ccbca39d0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5227436dc65d4a4783816756f62b57a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73052d77a0e24da8a02d8ad0e0965d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8334be333baf4ca0a753144fe56a8a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "333eb4c8865740c0842fc881927e08c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b9ca3b52e348e48f422dce16363270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b535c15950f8421ba1b93d0ee8188bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_377f8d9f3e22451d973be0655f0db8ab",
              "IPY_MODEL_c9797c150c2247e5bc466d180e55bbc8",
              "IPY_MODEL_f7941a66f3d0423baf249449290ebd8b"
            ],
            "layout": "IPY_MODEL_c9b82ecc7b8242df89438155ca6dc70d"
          }
        },
        "377f8d9f3e22451d973be0655f0db8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48cc4598651417ca263793012c8085b",
            "placeholder": "",
            "style": "IPY_MODEL_edafaab0c8244cc3a894e54770adfdc5",
            "value": "Map:100%"
          }
        },
        "c9797c150c2247e5bc466d180e55bbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32662dfc96d74e3886dc58463c82b7eb",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bdda221e4f74982bdd9b4dcf7a77966",
            "value": 200
          }
        },
        "f7941a66f3d0423baf249449290ebd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64be650161d84e85afed71718ad56c6b",
            "placeholder": "",
            "style": "IPY_MODEL_6fa804fee730444b9d616b4c2437be51",
            "value": "200/200[00:00&lt;00:00,1361.90examples/s]"
          }
        },
        "c9b82ecc7b8242df89438155ca6dc70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48cc4598651417ca263793012c8085b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edafaab0c8244cc3a894e54770adfdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32662dfc96d74e3886dc58463c82b7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bdda221e4f74982bdd9b4dcf7a77966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64be650161d84e85afed71718ad56c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa804fee730444b9d616b4c2437be51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb0eb0a9b07441c9cf84d15468043c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc8b481fa04843c8b407edd85da2302b",
              "IPY_MODEL_2a0cab7b57384ceeb26c8386321137ea",
              "IPY_MODEL_cb1b22d2788547ea9784794fe0c6938c"
            ],
            "layout": "IPY_MODEL_a25edfffd1da40cbb123477b39c0667b"
          }
        },
        "fc8b481fa04843c8b407edd85da2302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfda7f7df10648e4a5b0200f6d9cf833",
            "placeholder": "",
            "style": "IPY_MODEL_9ed8e1fca70b41d895612d35bebd69dc",
            "value": "Map:100%"
          }
        },
        "2a0cab7b57384ceeb26c8386321137ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7496a5ce6d5465e8668c9c1c8b8edc2",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6e3e2e5262d4f1c8689ad51072a2b9f",
            "value": 160
          }
        },
        "cb1b22d2788547ea9784794fe0c6938c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c81d99df7f48cb8d0c7eb9736c9196",
            "placeholder": "",
            "style": "IPY_MODEL_460fc8d910f246cdaf3eaa9fefd28fef",
            "value": "160/160[00:00&lt;00:00,733.74examples/s]"
          }
        },
        "a25edfffd1da40cbb123477b39c0667b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfda7f7df10648e4a5b0200f6d9cf833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed8e1fca70b41d895612d35bebd69dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7496a5ce6d5465e8668c9c1c8b8edc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e3e2e5262d4f1c8689ad51072a2b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c81d99df7f48cb8d0c7eb9736c9196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460fc8d910f246cdaf3eaa9fefd28fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28af4084336d4bdda68764b3ea08beee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0844ef1adf504e5185aa914e3d3ee1bd",
              "IPY_MODEL_9c92b0d8c0354ba795d2f79c3d178b83",
              "IPY_MODEL_c99f0bc3001a45b4b13a477e8452f999"
            ],
            "layout": "IPY_MODEL_44cb67d1a0fb48149ca84273a473ec52"
          }
        },
        "0844ef1adf504e5185aa914e3d3ee1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18046f2571824f1794c5ff42b1c88664",
            "placeholder": "",
            "style": "IPY_MODEL_c5874da151d444bdb427c40362e89aa3",
            "value": "Map:100%"
          }
        },
        "9c92b0d8c0354ba795d2f79c3d178b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a27b1777694242a97f43067d91dcf5",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293d601a10e148179f6a97ca7bacee90",
            "value": 40
          }
        },
        "c99f0bc3001a45b4b13a477e8452f999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3f7f7393e944af9067e3d904ccab29",
            "placeholder": "",
            "style": "IPY_MODEL_d22956668ad9468a9777611192991837",
            "value": "40/40[00:00&lt;00:00,514.23examples/s]"
          }
        },
        "44cb67d1a0fb48149ca84273a473ec52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18046f2571824f1794c5ff42b1c88664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5874da151d444bdb427c40362e89aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a27b1777694242a97f43067d91dcf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293d601a10e148179f6a97ca7bacee90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed3f7f7393e944af9067e3d904ccab29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22956668ad9468a9777611192991837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7707f4f9b8b4c9f828b9b4a9ea940d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d04bebd090e042018ee4790a78118f24",
              "IPY_MODEL_4082031b8ba94f24aaeee1d685cc4a1b",
              "IPY_MODEL_00cd310140fd4d089e28c5471cd7ae2c"
            ],
            "layout": "IPY_MODEL_e689f35d5b6a441eb61bb14d5a047476"
          }
        },
        "d04bebd090e042018ee4790a78118f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403d4298b28446e88baf7c2796d1ea9c",
            "placeholder": "",
            "style": "IPY_MODEL_15007e3fd02e419c8e2b2206b54dba3c",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "4082031b8ba94f24aaeee1d685cc4a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b021b0b1141040d197edabe3b163f902",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efb450aae8a745eb84a0f78c862f65a6",
            "value": 2
          }
        },
        "00cd310140fd4d089e28c5471cd7ae2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ddff403226b45328f4fc207f1b753b1",
            "placeholder": "",
            "style": "IPY_MODEL_d89e1eed90c544c1adf8ec3ab0bad919",
            "value": "2/2[00:23&lt;00:00,10.19s/it]"
          }
        },
        "e689f35d5b6a441eb61bb14d5a047476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403d4298b28446e88baf7c2796d1ea9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15007e3fd02e419c8e2b2206b54dba3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b021b0b1141040d197edabe3b163f902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb450aae8a745eb84a0f78c862f65a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ddff403226b45328f4fc207f1b753b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89e1eed90c544c1adf8ec3ab0bad919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}